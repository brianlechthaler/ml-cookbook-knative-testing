resources:
  cloud: nebius
  region: <region> # https://docs.nebius.com/overview/regions
  cpus: 16 # https://docs.nebius.com/compute/virtual-machines/types#cpu-configurations

num_nodes: 4 # amount of nodes to parallel download
workdir: .

envs:
  # =================================================
  # Required variables - must be set before launching
  # =================================================
  SOURCE_BUCKET: s3://<source-bucket-name>
  SOURCE_BUCKET_REGION: <region>
  SOURCE_BUCKET_ENDPOINT_URL: https://storage.<region>.nebius.cloud:443
  SOURCE_BUCKET_ACCESS_KEY_ID: <access-key-id>
  SOURCE_BUCKET_ACCESS_KEY: <access-key>
  DEST_DIR: /mnt/sfs
  # =================================================
  # Progress and ETA Configuration
  # =================================================
  PROGRESS_INTERVAL: 30  # Progress report interval in seconds
  ETA_UPDATE_INTERVAL: 60  # ETA update interval in seconds
  ENABLE_DETAILED_PROGRESS: true  # Enable detailed progress tracking
  ENABLE_CLUSTER_PROGRESS: true   # Enable cluster-wide progress monitoring

setup: |
  echo 'Installing required tools...'

  # Install latest rclone
  curl https://rclone.org/install.sh | sudo bash

  # Install other utilities
  sudo apt-get update -qq > /dev/null 2>&1
  sudo apt-get install -y jq bc htop iotop -qq > /dev/null 2>&1
  
  # Create rclone config directory
  mkdir -p ~/.config/rclone

  # Generate rclone config file
  echo "[s3]" > ~/.config/rclone/rclone.conf
  echo "type = s3" >> ~/.config/rclone/rclone.conf
  echo "provider = AWS" >> ~/.config/rclone/rclone.conf
  echo "env_auth = false" >> ~/.config/rclone/rclone.conf
  echo "region = ${SOURCE_BUCKET_REGION}" >> ~/.config/rclone/rclone.conf
  echo "no_check_bucket = true" >> ~/.config/rclone/rclone.conf
  echo "endpoint = ${SOURCE_BUCKET_ENDPOINT_URL}" >> ~/.config/rclone/rclone.conf
  echo "acl = private" >> ~/.config/rclone/rclone.conf
  echo "bucket_acl = private" >> ~/.config/rclone/rclone.conf
  echo "access_key_id = ${SOURCE_BUCKET_ACCESS_KEY_ID}" >> ~/.config/rclone/rclone.conf
  echo "secret_access_key = ${SOURCE_BUCKET_ACCESS_KEY}" >> ~/.config/rclone/rclone.conf

  echo "Rclone configuration file created successfully"

run: |
  # Configuration and environment setup
  export TASK_ID=${SKYPILOT_TASK_ID}
  export NODE_RANK=${SKYPILOT_NODE_RANK}
  export NUM_NODES=${SKYPILOT_NUM_NODES}
  # Export environment variables
  export SOURCE_BUCKET=${SOURCE_BUCKET}
  export SOURCE_BUCKET_ENDPOINT_URL=${SOURCE_BUCKET_ENDPOINT_URL}
  export SOURCE_BUCKET_ACCESS_KEY_ID=${SOURCE_BUCKET_ACCESS_KEY_ID}
  export SOURCE_BUCKET_ACCESS_KEY=${SOURCE_BUCKET_ACCESS_KEY}
  export DEST_DIR=${DEST_DIR}
  export PROGRESS_INTERVAL=${PROGRESS_INTERVAL:-30}
  export ETA_UPDATE_INTERVAL=${ETA_UPDATE_INTERVAL:-60}
  export ENABLE_DETAILED_PROGRESS=${ENABLE_DETAILED_PROGRESS:-true}
  export ENABLE_CLUSTER_PROGRESS=${ENABLE_CLUSTER_PROGRESS:-true}
  export SPEED_HISTORY_SIZE=${SPEED_HISTORY_SIZE:-5}

  export TEMP_DIR=${DEST_DIR}/s3migration
  sudo mkdir -p $TEMP_DIR
  sudo chmod 777 $TEMP_DIR

  # Verify directory creation and accessibility
  if [ ! -d "$TEMP_DIR" ]; then
    echo "Error: Failed to create temporary directory $TEMP_DIR"
    exit 1
  fi

  if [ ! -w "$TEMP_DIR" ]; then
    echo "Error: No write permission for temporary directory $TEMP_DIR"
    exit 1
  fi

  echo "Temporary directory $TEMP_DIR is available and writable"

  # Progress tracking functions
  progress_log() {
    local level=$1
    shift
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [NODE-${NODE_RANK}] [$level] $*"
  }

  calculate_eta() {
    local elapsed=$1
    local completed=$2
    local total=$3
    
    if [ "$completed" -eq 0 ]; then
      echo "∞"
      return
    fi
    
    local rate=$(echo "scale=2; $completed / $elapsed" | bc -l)
    local remaining=$(echo "scale=0; $total - $completed" | bc -l)
    local eta_seconds=$(echo "scale=0; $remaining / $rate" | bc -l)
    
    if [ "$eta_seconds" -lt 0 ]; then
      echo "∞"
      return
    fi
    
    local hours=$((eta_seconds / 3600))
    local minutes=$(((eta_seconds % 3600) / 60))
    local seconds=$((eta_seconds % 60))
    
    if [ $hours -gt 0 ]; then
      echo "${hours}h ${minutes}m ${seconds}s"
    elif [ $minutes -gt 0 ]; then
      echo "${minutes}m ${seconds}s"
    else
      echo "${seconds}s"
    fi
  }

  format_bytes() {
    local bytes=$1
    if [ $bytes -gt 1099511627776 ]; then
      echo "$(echo "scale=2; $bytes / 1099511627776" | bc -l) TB"
    elif [ $bytes -gt 1073741824 ]; then
      echo "$(echo "scale=2; $bytes / 1073741824" | bc -l) GB"
    elif [ $bytes -gt 1048576 ]; then
      echo "$(echo "scale=2; $bytes / 1048576" | bc -l) MB"
    elif [ $bytes -gt 1024 ]; then
      echo "$(echo "scale=2; $bytes / 1024" | bc -l) KB"
    else
      echo "${bytes} B"
    fi
  }

  format_percentage() {
    local completed=$1
    local total=$2
    if [ "$total" -eq 0 ]; then
      echo "0.00%"
    else
      echo "$(echo "scale=2; $completed * 100 / $total" | bc -l)%"
    fi
  }

  # Calculate average speed from history (unused - kept for reference)
  calculate_average_speed() {
    local node_rank=$1
    local history_size=$2
    
    # Get the last N speed readings for this node
    local total_speed=0
    local valid_readings=0
    
    # Read the last N speed values from the history file
    if [ -f "$TEMP_DIR/node_${node_rank}_speed_history" ]; then
      local speed_values=$(tail -$history_size "$TEMP_DIR/node_${node_rank}_speed_history" 2>/dev/null)
      for speed in $speed_values; do
        if [ "$speed" -gt 0 ] 2>/dev/null; then
          total_speed=$((total_speed + speed))
          valid_readings=$((valid_readings + 1))
        fi
      done
    fi
    
    # Return average speed if we have valid readings
    if [ "$valid_readings" -gt 0 ]; then
      local avg_speed=$((total_speed / valid_readings))
      echo "$avg_speed"
    else
      echo "0"
    fi
  }

  # Progress monitoring function
  monitor_progress() {
    local node_objects_file=$1
    local progress_file=$2
    local start_time=$3
    local total_objects=$4
    local total_size=$5
    
    progress_log "INFO" "Starting progress monitoring for node ${NODE_RANK}"
    
    while true; do
      if [ -f "$progress_file" ]; then
        # Read current progress
        local current_objects=$(cat "$progress_file" 2>/dev/null || echo "0")
        local current_size=$(cat "${progress_file}_size" 2>/dev/null || echo "0")
        local current_time=$(date +%s)
        local elapsed=$((current_time - start_time))
        
        # Calculate progress percentages
        local obj_percentage=$(format_percentage $current_objects $total_objects)
        local size_percentage=$(format_percentage $current_size $total_size)
        
        # Calculate ETA
        local eta_objects=$(calculate_eta $elapsed $current_objects $total_objects)
        local eta_size=$(calculate_eta $elapsed $current_size $total_size)
        
        # Calculate transfer rates
        local obj_rate=$(echo "scale=2; $current_objects / $elapsed" | bc -l 2>/dev/null || echo "0")
        local size_rate=$(echo "scale=2; $current_size / $elapsed" | bc -l 2>/dev/null || echo "0")
        
        # Format rates
        local obj_rate_fmt=$(echo "scale=2; $obj_rate" | bc -l 2>/dev/null || echo "0")
        local size_rate_fmt=$(format_bytes $size_rate)
        
        # Log progress
        progress_log "PROGRESS" "Objects: $current_objects/$total_objects ($obj_percentage) | Size: $(format_bytes $current_size)/$(format_bytes $total_size) ($size_percentage)"
        progress_log "PROGRESS" "Rate: ${obj_rate_fmt} obj/s, ${size_rate_fmt}/s | ETA: Objects=$eta_objects, Size=$eta_size"
        
        # Check if completed
        if [ "$current_objects" -ge "$total_objects" ]; then
          progress_log "INFO" "Node ${NODE_RANK} completed all transfers"
          break
        fi
      fi
      
      sleep $PROGRESS_INTERVAL
    done
  }

  # Parse rclone log for statistics (silent - no output)
  parse_rclone_log() {
    local log_file=$1
    local node_rank=$2
    
    if [ ! -f "$log_file" ]; then
      return 1
    fi
    
    # Extract the last progress line with "Transferred:" or individual file progress
    local last_progress=$(tail -10 "$log_file" 2>/dev/null | grep -E "(Transferred:|[0-9]+% /[0-9.]+[KMGT]i)" | tail -1 || echo "")
    if [ -n "$last_progress" ]; then
      # Try to parse "Transferred:" format first
      if echo "$last_progress" | grep -q "Transferred:"; then
        local transferred=$(echo "$last_progress" | grep -o 'Transferred:[[:space:]]*[0-9]*' | grep -o '[0-9]*')
        local size=$(echo "$last_progress" | grep -o 'size:[[:space:]]*[0-9]*' | grep -o '[0-9]*')
        local eta=$(echo "$last_progress" | grep -o 'ETA:[[:space:]]*[0-9]*[hm]*[[:space:]]*[0-9]*[ms]*' | sed 's/ETA:[[:space:]]*//')
        
        if [ -n "$transferred" ] && [ "$transferred" -ge 0 ]; then
          echo "$transferred" > $TEMP_DIR/node_${node_rank}_progress
          echo "$size" > $TEMP_DIR/node_${node_rank}_progress_size
          echo "$eta" > $TEMP_DIR/node_${node_rank}_eta
          return 0
        fi
      else
        # Parse individual file progress format (e.g., "part-000086.zip: 74% /663.815Mi, 48.300Mi/s, 3s")
        local file_progress=$(echo "$last_progress" | grep -o '[0-9]+%' | grep -o '[0-9]*')
        local file_size=$(echo "$last_progress" | grep -o '/[0-9.]+[KMGT]i' | sed 's|/||')
        local file_speed=$(echo "$last_progress" | grep -o '[0-9.]+[KMGT]i/s')
        local file_eta=$(echo "$last_progress" | grep -o '[0-9]+s$')
        
        if [ -n "$file_progress" ]; then
          # Estimate total progress based on file progress
          local estimated_objects=$(echo "scale=0; $file_progress * $NODE_TOTAL_OBJECTS / 100" | bc -l)
          echo "$estimated_objects" > $TEMP_DIR/node_${node_rank}_progress
          echo "$file_size" > $TEMP_DIR/node_${node_rank}_progress_size
          echo "$file_eta" > $TEMP_DIR/node_${node_rank}_eta
          return 0
        fi
      fi
    fi
    
    return 1
  }

  # Cluster progress monitoring (head node only)
  monitor_cluster_progress() {
    local start_time=$1
    local total_objects=$2
    local total_size=$3
    
    progress_log "INFO" "Starting cluster-wide progress monitoring"
    progress_log "INFO" "Cluster monitor will check every $ETA_UPDATE_INTERVAL seconds"
    
    while true; do
      progress_log "DEBUG" "Cluster monitor checking progress files..."
      local cluster_objects=0
      local cluster_size=0
      local completed_nodes=0
      
      # Aggregate progress from all nodes
      for i in $(seq 0 $((NUM_NODES-1))); do
        local node_progress_file="$TEMP_DIR/node_${i}_progress"
        if [ -f "$node_progress_file" ]; then
          local node_objects=$(cat "$node_progress_file" 2>/dev/null || echo "0")
          local node_size=$(cat "${node_progress_file}_size" 2>/dev/null || echo "0")
          cluster_objects=$((cluster_objects + node_objects))
          cluster_size=$((cluster_size + node_size))
          
          progress_log "DEBUG" "Node $i: objects=$node_objects, size=$node_size"
          
          if [ "$node_objects" -ge "$(cat $TEMP_DIR/node_${i}_total_objects 2>/dev/null || echo "0")" ]; then
            completed_nodes=$((completed_nodes + 1))
          fi
        else
          progress_log "DEBUG" "Node $i progress file not found: $node_progress_file"
        fi
      done
      
      local current_time=$(date +%s)
      local elapsed=$((current_time - start_time))
      
      # Calculate cluster progress
      local obj_percentage=$(format_percentage $cluster_objects $total_objects)
      local size_percentage=$(format_percentage $cluster_size $total_size)
      local eta_objects=$(calculate_eta $elapsed $cluster_objects $total_objects)
      local eta_size=$(calculate_eta $elapsed $cluster_size $total_size)
      
      # Calculate cluster transfer rates
      local obj_rate=$(echo "scale=2; $cluster_objects / $elapsed" | bc -l 2>/dev/null || echo "0")
      local size_rate=$(echo "scale=2; $cluster_size / $elapsed" | bc -l 2>/dev/null || echo "0")
      
      # Log cluster progress
      echo "=================================================="
      progress_log "CLUSTER" "Overall Progress: $cluster_objects/$total_objects objects ($obj_percentage)"
      progress_log "CLUSTER" "Overall Size: $(format_bytes $cluster_size)/$(format_bytes $total_size) ($size_percentage)"
      progress_log "CLUSTER" "Completed Nodes: $completed_nodes/$NUM_NODES"
      progress_log "CLUSTER" "Cluster Rate: ${obj_rate} obj/s, $(format_bytes $size_rate)/s"
      progress_log "CLUSTER" "Cluster ETA: Objects=$eta_objects, Size=$eta_size"
      echo "=================================================="
      
      # Debug: Show individual node progress
      for i in $(seq 0 $((NUM_NODES-1))); do
        local node_progress_file="$TEMP_DIR/node_${i}_progress"
        if [ -f "$node_progress_file" ]; then
          local node_objects=$(cat "$node_progress_file" 2>/dev/null || echo "0")
          progress_log "DEBUG" "Node $i progress: $node_objects objects"
        fi
      done
      
      # Check if all nodes completed
      if [ "$completed_nodes" -eq "$NUM_NODES" ]; then
        progress_log "INFO" "All nodes completed - cluster migration finished"
        break
      fi
      
      sleep $ETA_UPDATE_INTERVAL
    done
  }

  echo "Starting S3 to SFS migration task on node ${NODE_RANK}..."
  
  # Record start time
  START_TIME=$(date +%s)

  echo "Starting S3 migration task: ${TASK_ID}"
  echo "Running on node ${NODE_RANK} of ${NUM_NODES} nodes"
  echo "Migration started at $(date)"
  echo "Progress monitoring enabled: $ENABLE_DETAILED_PROGRESS"
  echo "Cluster progress monitoring enabled: $ENABLE_CLUSTER_PROGRESS"

  # Head node lists all objects and distributes work
  if [ "${NODE_RANK}" = "0" ]; then
    progress_log "INFO" "Head node: Listing all objects in source bucket"
    
    # List all objects
    rclone lsf $SOURCE_BUCKET --files-only --format sp --recursive > $TEMP_DIR/all_objects.txt
    
    # Count total objects and calculate estimated size
    TOTAL_OBJECTS=$(wc -l < $TEMP_DIR/all_objects.txt)
    TOTAL_SIZE_BYTES=$(awk '{sum += $1} END {print sum}' $TEMP_DIR/all_objects.txt)
    TOTAL_SIZE_GB=$(echo "scale=2; $TOTAL_SIZE_BYTES / 1024 / 1024 / 1024" | bc)
    
    progress_log "INFO" "Found $TOTAL_OBJECTS objects with total size of approximately $TOTAL_SIZE_GB GB"
    
    # Store total counts for progress tracking
    echo $TOTAL_OBJECTS > $TEMP_DIR/total_objects
    echo $TOTAL_SIZE_BYTES > $TEMP_DIR/total_size_bytes
    
    # Distribute objects evenly among nodes
    progress_log "INFO" "Distributing objects among $NUM_NODES nodes"
    
    # Split files by node using modulo on line number
    for i in $(seq 0 $((NUM_NODES-1))); do
      awk -v node=$i -v nodes=$NUM_NODES 'NR % nodes == node' $TEMP_DIR/all_objects.txt > $TEMP_DIR/node_${i}_objects.txt
      
      # Count files and total size for this node
      NODE_OBJECTS=$(wc -l < $TEMP_DIR/node_${i}_objects.txt)
      NODE_SIZE_BYTES=$(awk '{sum += $1} END {print sum}' $TEMP_DIR/node_${i}_objects.txt)
      NODE_SIZE_GB=$(echo "scale=2; $NODE_SIZE_BYTES / 1024 / 1024 / 1024" | bc)
      
      # Store node-specific totals for progress tracking
      echo $NODE_OBJECTS > $TEMP_DIR/node_${i}_total_objects
      echo $NODE_SIZE_BYTES > $TEMP_DIR/node_${i}_total_size_bytes
      
      progress_log "INFO" "Node $i assigned $NODE_OBJECTS objects with total size of approximately $NODE_SIZE_GB GB"
    done
    progress_log "INFO" "Object distribution complete."
    
    # Signal that all node files are ready
    echo "ready" > $TEMP_DIR/node_distribution_complete
    
    # Start cluster progress monitoring in background if enabled
    if [ "$ENABLE_CLUSTER_PROGRESS" = "true" ]; then
      progress_log "INFO" "Starting cluster progress monitoring..."
      progress_log "INFO" "Cluster monitoring params: start_time=$START_TIME, total_objects=$TOTAL_OBJECTS, total_size=$TOTAL_SIZE_BYTES"
      monitor_cluster_progress $START_TIME $TOTAL_OBJECTS $TOTAL_SIZE_BYTES &
      CLUSTER_MONITOR_PID=$!
      progress_log "INFO" "Cluster progress monitoring started with PID $CLUSTER_MONITOR_PID"
      
      # Test if cluster monitor is running
      sleep 2
      if kill -0 $CLUSTER_MONITOR_PID 2>/dev/null; then
        progress_log "INFO" "Cluster monitor process is running"
      else
        progress_log "ERROR" "Cluster monitor process failed to start"
      fi
    else
      progress_log "WARNING" "Cluster progress monitoring is DISABLED"
    fi
  fi
  
  # Workers wait for head node to assign files to workers
  if [ "${NODE_RANK}" -gt "0" ]; then
    progress_log "INFO" "Worker node ${NODE_RANK}: Waiting for object list assignment..."
    while [ ! -f "$TEMP_DIR/node_${NODE_RANK}_objects.txt" ]; do
      sleep 10
    done
    progress_log "INFO" "Worker node ${NODE_RANK}: Received object list assignment."
    
    # Wait for progress tracking files to be created by head node
    progress_log "INFO" "Worker node ${NODE_RANK}: Waiting for progress tracking files..."
    while [ ! -f "$TEMP_DIR/node_distribution_complete" ]; do
      sleep 5
    done
    progress_log "INFO" "Worker node ${NODE_RANK}: Progress tracking files ready."
  fi

  # Each node processes its assigned files with progress tracking
  progress_log "INFO" "Processing node ${NODE_RANK}"
  
  # Get node-specific totals (with safety check for head node)
  if [ "${NODE_RANK}" = "0" ]; then
    # Head node waits for its own progress tracking files to be created
    while [ ! -f "$TEMP_DIR/node_${NODE_RANK}_total_objects" ] || [ ! -f "$TEMP_DIR/node_${NODE_RANK}_total_size_bytes" ]; do
      sleep 1
    done
  fi
  
  NODE_TOTAL_OBJECTS=$(cat $TEMP_DIR/node_${NODE_RANK}_total_objects)
  NODE_TOTAL_SIZE=$(cat $TEMP_DIR/node_${NODE_RANK}_total_size_bytes)
  
  # Validate that we have valid totals
  if [ -z "$NODE_TOTAL_OBJECTS" ] || [ "$NODE_TOTAL_OBJECTS" -eq 0 ]; then
    progress_log "ERROR" "Invalid total objects count for node ${NODE_RANK}: $NODE_TOTAL_OBJECTS"
    exit 1
  fi
  
  if [ -z "$NODE_TOTAL_SIZE" ]; then
    progress_log "ERROR" "Invalid total size for node ${NODE_RANK}: $NODE_TOTAL_SIZE"
    exit 1
  fi
  
  progress_log "INFO" "Node ${NODE_RANK} will process $NODE_TOTAL_OBJECTS objects with total size $(format_bytes $NODE_TOTAL_SIZE)"
  
  # Initialize progress files
  echo "0" > $TEMP_DIR/node_${NODE_RANK}_progress
  echo "0" > $TEMP_DIR/node_${NODE_RANK}_progress_size
  
  # Start progress monitoring in background if enabled
  if [ "$ENABLE_DETAILED_PROGRESS" = "true" ]; then
    progress_log "INFO" "Starting background progress monitoring for node ${NODE_RANK}"
    monitor_progress $TEMP_DIR/node_${NODE_RANK}_objects.txt $TEMP_DIR/node_${NODE_RANK}_progress $START_TIME $NODE_TOTAL_OBJECTS $NODE_TOTAL_SIZE &
    PROGRESS_MONITOR_PID=$!
    progress_log "INFO" "Background progress monitoring started with PID $PROGRESS_MONITOR_PID"
  else
    # Simple progress monitoring for non-detailed mode
    progress_log "INFO" "Starting simple progress monitoring for node ${NODE_RANK}"
    (
      while true; do
        sleep $PROGRESS_INTERVAL
        if [ -f "$RCLONE_LOG_FILE" ]; then
          parse_rclone_log "$RCLONE_LOG_FILE" "$NODE_RANK"
        fi
      done
    ) &
    SIMPLE_MONITOR_PID=$!
    progress_log "INFO" "Simple progress monitoring started with PID $SIMPLE_MONITOR_PID"
  fi
  
  # Create file list for rclone
  progress_log "INFO" "Creating file list for rclone from node_${NODE_RANK}_objects.txt"
  cut -d';' -f2 $TEMP_DIR/node_${NODE_RANK}_objects.txt > $TEMP_DIR/node_${NODE_RANK}_list.txt
  
  # Verify file list was created
  LIST_COUNT=$(wc -l < $TEMP_DIR/node_${NODE_RANK}_list.txt)
  progress_log "INFO" "Created file list with $LIST_COUNT files for node ${NODE_RANK}"
  
  # Show first few files for debugging
  progress_log "INFO" "First 3 files in list:"
  head -3 $TEMP_DIR/node_${NODE_RANK}_list.txt | while read file; do
    progress_log "INFO" "  - $file"
  done
  
  # Test rclone connectivity
  progress_log "INFO" "Testing rclone connectivity to source bucket..."
  if rclone lsf $SOURCE_BUCKET --max-depth=1 --files-only | head -1 > /dev/null 2>&1; then
    progress_log "INFO" "Rclone connectivity test successful"
  else
    progress_log "ERROR" "Rclone connectivity test failed - cannot access source bucket"
    exit 1
  fi
  
  # Run rclone with progress tracking
  progress_log "INFO" "Starting rclone copy for node ${NODE_RANK}"
  
  # Create log files for rclone output
  RCLONE_LOG_FILE="$TEMP_DIR/node_${NODE_RANK}_rclone.log"
  RCLONE_PROGRESS_FILE="$TEMP_DIR/node_${NODE_RANK}_rclone_progress.log"
  
  progress_log "INFO" "Rclone logs will be written to: $RCLONE_LOG_FILE"
  progress_log "INFO" "Rclone progress will be written to: $RCLONE_PROGRESS_FILE"
  
  if [ "$ENABLE_DETAILED_PROGRESS" = "true" ]; then
    # Use rclone with progress output and log to files
    progress_log "INFO" "Running rclone with detailed progress tracking and file logging"
    
    # Start rclone in background with logging
    rclone copy --files-from $TEMP_DIR/node_${NODE_RANK}_list.txt $SOURCE_BUCKET $DEST_DIR \
      --links --disable-http2 --transfers=128 --stats=30 --progress \
      --log-level=INFO > "$RCLONE_LOG_FILE" 2>&1 &
    RCLONE_PID=$!
    
    progress_log "INFO" "Rclone started with PID $RCLONE_PID"
    
    # Monitor rclone progress by parsing the log file
    while kill -0 $RCLONE_PID 2>/dev/null; do
      if [ -f "$RCLONE_LOG_FILE" ]; then
        # Extract latest progress from log
        LATEST_PROGRESS=$(tail -1 "$RCLONE_LOG_FILE" 2>/dev/null | grep "Transferred:" || echo "")
        if [ -n "$LATEST_PROGRESS" ]; then
          # Parse progress line
          TRANSFERRED=$(echo "$LATEST_PROGRESS" | grep -o 'Transferred:[[:space:]]*[0-9]*' | grep -o '[0-9]*')
          SIZE=$(echo "$LATEST_PROGRESS" | grep -o 'size:[[:space:]]*[0-9]*' | grep -o '[0-9]*')
          ETA=$(echo "$LATEST_PROGRESS" | grep -o 'ETA:[[:space:]]*[0-9]*[hm]*[[:space:]]*[0-9]*[ms]*' | sed 's/ETA:[[:space:]]*//')
          
          if [ -n "$TRANSFERRED" ] && [ "$TRANSFERRED" -ge 0 ]; then
            echo "$TRANSFERRED" > $TEMP_DIR/node_${NODE_RANK}_progress
            echo "$SIZE" > $TEMP_DIR/node_${NODE_RANK}_progress_size
            echo "$ETA" > $TEMP_DIR/node_${NODE_RANK}_eta
            
            # Log progress
            progress_log "PROGRESS" "Rclone: $TRANSFERRED/$NODE_TOTAL_OBJECTS objects, $(format_bytes $SIZE), ETA: $ETA"
          fi
        fi
      fi
      sleep $PROGRESS_INTERVAL
    done
    
    # Wait for rclone to complete
    wait $RCLONE_PID
    RCLONE_EXIT_CODE=$?
    
    if [ $RCLONE_EXIT_CODE -eq 0 ]; then
      progress_log "INFO" "Rclone copy completed successfully for node ${NODE_RANK}"
    else
      progress_log "ERROR" "Rclone copy failed for node ${NODE_RANK} with exit code $RCLONE_EXIT_CODE"
      progress_log "ERROR" "Last 10 lines of rclone log:"
      tail -10 "$RCLONE_LOG_FILE" | while read line; do
        progress_log "ERROR" "  $line"
      done
      exit 1
    fi
  else
    # Run without detailed progress tracking but still log to file
    progress_log "INFO" "Running rclone without detailed progress tracking"
    
    # Start rclone in background with timeout monitoring
    progress_log "INFO" "About to start rclone command..."
    progress_log "INFO" "Command: rclone copy --files-from $TEMP_DIR/node_${NODE_RANK}_list.txt $SOURCE_BUCKET $DEST_DIR --links --disable-http2 --transfers=128 --stats=0 --log-level=ERROR"
    
    # Test if the file list is readable
    if [ ! -f "$TEMP_DIR/node_${NODE_RANK}_list.txt" ]; then
      progress_log "ERROR" "File list not found: $TEMP_DIR/node_${NODE_RANK}_list.txt"
      exit 1
    fi
    
    # Test if we can read the first few lines
    progress_log "INFO" "Testing file list readability..."
    head -3 "$TEMP_DIR/node_${NODE_RANK}_list.txt" | while read file; do
      progress_log "INFO" "  File: $file"
    done
    
    # Test if rclone can list the first file
    progress_log "INFO" "Testing rclone access to first file..."
    FIRST_FILE=$(head -1 "$TEMP_DIR/node_${NODE_RANK}_list.txt")
    if [ -n "$FIRST_FILE" ]; then
      progress_log "INFO" "Testing access to: $SOURCE_BUCKET/$FIRST_FILE"
      if rclone lsf "$SOURCE_BUCKET/$FIRST_FILE" > /dev/null 2>&1; then
        progress_log "INFO" "Successfully accessed first file"
      else
        progress_log "ERROR" "Failed to access first file: $SOURCE_BUCKET/$FIRST_FILE"
        exit 1
      fi
    fi
    
    # Try a simpler rclone command first to test
    progress_log "INFO" "Testing simple rclone command..."
    if rclone lsf $SOURCE_BUCKET --max-depth=1 --files-only | head -5 > /dev/null 2>&1; then
      progress_log "INFO" "Simple rclone test successful"
    else
      progress_log "ERROR" "Simple rclone test failed"
      exit 1
    fi
    
    # Check the file list format
    progress_log "INFO" "Checking file list format..."
    head -5 "$TEMP_DIR/node_${NODE_RANK}_list.txt" | while read file; do
      progress_log "INFO" "  File: '$file'"
    done
    
    # Try rclone with verbose logging to see what's happening
    progress_log "INFO" "Starting rclone with verbose logging..."
    
    # First, try copying just one file to test
    FIRST_FILE=$(head -1 "$TEMP_DIR/node_${NODE_RANK}_list.txt")
    if [ -n "$FIRST_FILE" ]; then
      progress_log "INFO" "Testing single file copy: $SOURCE_BUCKET/$FIRST_FILE"
      if rclone copy "$SOURCE_BUCKET/$FIRST_FILE" "$DEST_DIR/" --log-level=INFO > /tmp/single_test.log 2>&1; then
        progress_log "INFO" "Single file copy test successful"
      else
        progress_log "ERROR" "Single file copy test failed"
        progress_log "ERROR" "Single file test log:"
        cat /tmp/single_test.log | while read line; do
          progress_log "ERROR" "  $line"
        done
        exit 1
      fi
    fi
    
    rclone copy --files-from $TEMP_DIR/node_${NODE_RANK}_list.txt $SOURCE_BUCKET $DEST_DIR \
      --links --disable-http2 --transfers=4 --stats=30 --progress \
      --log-level=INFO > "$RCLONE_LOG_FILE" 2>&1 &
    RCLONE_PID=$!
    
    progress_log "INFO" "Rclone started with PID $RCLONE_PID"
    
    # Check if process started successfully
    sleep 2
    
    # Test progress parsing immediately
    progress_log "INFO" "Testing initial progress parsing..."
    if [ -f "$RCLONE_LOG_FILE" ]; then
      parse_rclone_log "$RCLONE_LOG_FILE" "$NODE_RANK"
    else
      progress_log "INFO" "Rclone log not ready yet, will retry in $PROGRESS_INTERVAL seconds"
    fi
    if kill -0 $RCLONE_PID 2>/dev/null; then
      progress_log "INFO" "Rclone process $RCLONE_PID is running"
    else
      progress_log "ERROR" "Rclone process failed to start or died immediately"
      if [ -f "$RCLONE_LOG_FILE" ]; then
        progress_log "ERROR" "Rclone log contents:"
        cat "$RCLONE_LOG_FILE" | while read line; do
          progress_log "ERROR" "  $line"
        done
      fi
      exit 1
    fi
    
    # Monitor rclone process with timeout
    timeout_counter=0
    max_timeout=60  # 1 minute timeout for faster debugging
    
    while kill -0 $RCLONE_PID 2>/dev/null; do
      sleep $PROGRESS_INTERVAL
      timeout_counter=$((timeout_counter + PROGRESS_INTERVAL))
      
      # Check if log file is being written to
      if [ -f "$RCLONE_LOG_FILE" ]; then
        log_size=$(stat -c%s "$RCLONE_LOG_FILE" 2>/dev/null || echo "0")
        if [ "$log_size" -gt 0 ]; then
          timeout_counter=0  # Reset timeout if we see activity
        fi
      fi
      
      # Check for timeout
      if [ "$timeout_counter" -ge "$max_timeout" ]; then
        progress_log "ERROR" "Rclone process timeout after ${max_timeout} seconds"
        progress_log "ERROR" "Killing rclone process $RCLONE_PID"
        kill -9 $RCLONE_PID 2>/dev/null || true
        progress_log "ERROR" "Rclone log file contents:"
        if [ -f "$RCLONE_LOG_FILE" ]; then
          cat "$RCLONE_LOG_FILE" | while read line; do
            progress_log "ERROR" "  $line"
          done
        else
          progress_log "ERROR" "  No log file found"
        fi
        exit 1
      fi
      
      # Show only clean progress lines
      if [ -f "$RCLONE_LOG_FILE" ]; then
        # Show only clean log lines with file progress
        tail -10 "$RCLONE_LOG_FILE" | grep -E "[0-9]+% /[0-9.]+[KMGT]i" | tail -1 | while read line; do
          # Remove leading spaces and asterisks from rclone output
          clean_line=$(echo "$line" | sed 's/^\s*\*\s*//')
          if [ -n "$clean_line" ]; then
            progress_log "INFO" "Log: $clean_line"
          fi
        done
      fi
      
      # Calculate and display cluster ETA based on current speed (silent calculation)
      if [ -f "$RCLONE_LOG_FILE" ]; then
        # Extract current speed from log
        current_speed_line=$(tail -10 "$RCLONE_LOG_FILE" | grep -E "[0-9]+% /[0-9.]+[KMGT]i" | tail -1)
        if [ -n "$current_speed_line" ]; then
          # Clean the line first (remove leading spaces and asterisks)
          clean_speed_line=$(echo "$current_speed_line" | sed 's/^\s*\*\s*//')
          # Extract speed using a simpler approach
          # Look for pattern like "47.666Mi/s" or "0/s" in the line
          speed=$(echo "$clean_speed_line" | sed -n 's/.*, \([0-9.]*[KMGT]*i\/s\).*/\1/p')
          
          # Alternative extraction method
          alt_speed=$(echo "$clean_speed_line" | awk -F', ' '{for(i=1;i<=NF;i++) if($i ~ /[0-9]+\.[0-9]+[KMGT]i\/s/) print $i}')
          
          # Use alternative speed if primary failed
          if [ -z "$speed" ] && [ -n "$alt_speed" ]; then
            speed="$alt_speed"
          fi
          
          if [ -n "$speed" ] && [ "$speed" != "0/s" ] && [ "$speed" != "-" ]; then
            # Convert speed to bytes for calculation
            speed_value=$(echo "$speed" | sed 's/Mi\/s//')
            speed_bytes=$(printf "%.0f" "$(echo "$speed_value * 1024 * 1024" | bc -l)")
            total_size_bytes=$NODE_TOTAL_SIZE
            
            # Calculate ETA based on current speed
            if [ "$speed_bytes" -gt 0 ]; then
              eta_seconds=$(printf "%.0f" "$(echo "$total_size_bytes / $speed_bytes" | bc -l)")
              eta_formatted=$(calculate_eta 0 0 $eta_seconds)
              
              # Store speed for cluster calculation
              echo "$speed_bytes" > $TEMP_DIR/node_${NODE_RANK}_speed
              # Add to speed history for averaging
              echo "$speed_bytes" >> $TEMP_DIR/node_${NODE_RANK}_speed_history
              # Keep only the last N readings
              if [ -f "$TEMP_DIR/node_${NODE_RANK}_speed_history" ]; then
                tail -$SPEED_HISTORY_SIZE "$TEMP_DIR/node_${NODE_RANK}_speed_history" > "$TEMP_DIR/node_${NODE_RANK}_speed_history.tmp"
                mv "$TEMP_DIR/node_${NODE_RANK}_speed_history.tmp" "$TEMP_DIR/node_${NODE_RANK}_speed_history"
              fi
            fi
          else
            # If no valid speed, clear the speed file
            rm -f $TEMP_DIR/node_${NODE_RANK}_speed
          fi
        fi
      fi
      
      # Calculate cluster-wide ETA (head node only, every 30 seconds)
      if [ "${NODE_RANK}" = "0" ] && [ $((timeout_counter % 30)) -eq 0 ]; then
        cluster_total_speed=0
        active_nodes=0
        running_nodes=0
        
        # Sum up average speeds from all nodes
        for i in $(seq 0 $((NUM_NODES-1))); do
          speed_file="$TEMP_DIR/node_${i}_speed"
          history_file="$TEMP_DIR/node_${i}_speed_history"
          # Check if node is running (has a done file or speed file)
          if [ -f "$speed_file" ] || [ -f "$TEMP_DIR/node_${i}_done" ]; then
            running_nodes=$((running_nodes + 1))
            if [ -f "$speed_file" ]; then
              # Use average speed instead of current speed (inline calculation)
              node_current_speed=$(cat "$speed_file" 2>/dev/null || echo "0")
              
              # Calculate average speed inline
              node_avg_speed=0
              if [ -f "$history_file" ]; then
                # Get the last N speed values and calculate average
                total_speed=0
                valid_readings=0
                speed_values=$(tail -$SPEED_HISTORY_SIZE "$history_file" 2>/dev/null)
                for speed in $speed_values; do
                  if [ "$speed" -gt 0 ] 2>/dev/null; then
                    total_speed=$((total_speed + speed))
                    valid_readings=$((valid_readings + 1))
                  fi
                done
                if [ "$valid_readings" -gt 0 ]; then
                  node_avg_speed=$((total_speed / valid_readings))
                fi
              fi
              
              # Use average speed for cluster calculation
              if [ "$node_avg_speed" -gt 0 ] 2>/dev/null; then
                cluster_total_speed=$((cluster_total_speed + node_avg_speed))
                active_nodes=$((active_nodes + 1))
              fi
            fi
          fi
        done
        
        # Calculate cluster ETA if we have active nodes
        if [ "$active_nodes" -gt 0 ] && [ "$cluster_total_speed" -gt 0 ]; then
          # Get total size from head node
          total_cluster_size=$(cat $TEMP_DIR/total_size_bytes 2>/dev/null || echo "0")
          if [ "$total_cluster_size" -gt 0 ]; then
            cluster_eta_seconds=$(printf "%.0f" "$(echo "$total_cluster_size / $cluster_total_speed" | bc -l)")
            # Only show ETA if it's a reasonable value (not infinity)
            if [ "$cluster_eta_seconds" -gt 0 ] && [ "$cluster_eta_seconds" -lt 999999 ]; then
              # Format ETA manually since calculate_eta expects elapsed/completed/total
              hours=$((cluster_eta_seconds / 3600))
              minutes=$(((cluster_eta_seconds % 3600) / 60))
              seconds=$((cluster_eta_seconds % 60))
              
              if [ "$hours" -gt 0 ]; then
                cluster_eta_formatted="${hours}h ${minutes}m ${seconds}s"
              elif [ "$minutes" -gt 0 ]; then
                cluster_eta_formatted="${minutes}m ${seconds}s"
              else
                cluster_eta_formatted="${seconds}s"
              fi
              
              cluster_speed_mb=$(echo "scale=2; $cluster_total_speed / 1024 / 1024" | bc -l)
              
              echo "=================================================="
              progress_log "CLUSTER_ETA" "Cluster avg speed: ${cluster_speed_mb} MB/s (${active_nodes}/${running_nodes} nodes active)"
              progress_log "CLUSTER_ETA" "Cluster ETA: $cluster_eta_formatted"
              echo "=================================================="
            fi
          fi
        fi
      fi
    done
    
    # Wait for rclone to complete
    wait $RCLONE_PID
    RCLONE_EXIT_CODE=$?
    
    if [ $RCLONE_EXIT_CODE -eq 0 ]; then
      progress_log "INFO" "Rclone copy completed successfully for node ${NODE_RANK}"
    else
      progress_log "ERROR" "Rclone copy failed for node ${NODE_RANK} with exit code $RCLONE_EXIT_CODE"
      progress_log "ERROR" "Last 10 lines of rclone log:"
      if [ -f "$RCLONE_LOG_FILE" ]; then
        tail -10 "$RCLONE_LOG_FILE" | while read line; do
          progress_log "ERROR" "  $line"
        done
      else
        progress_log "ERROR" "  No log file found"
      fi
      exit 1
    fi
  fi
  
  # Mark node as completed
  echo "done" > $TEMP_DIR/node_${NODE_RANK}_done
  
  # Wait for progress monitor to finish if it was started
  if [ "$ENABLE_DETAILED_PROGRESS" = "true" ] && [ -n "$PROGRESS_MONITOR_PID" ]; then
    wait $PROGRESS_MONITOR_PID
  elif [ "$ENABLE_DETAILED_PROGRESS" = "false" ] && [ -n "$SIMPLE_MONITOR_PID" ]; then
    kill $SIMPLE_MONITOR_PID 2>/dev/null || true
  fi

  # Head node verifies all nodes have completed
  if [ "${NODE_RANK}" = "0" ]; then
    progress_log "INFO" "Head node: Waiting for all worker nodes to complete"
    
    # Wait for all workers to complete
    for worker in $(seq 1 $((NUM_NODES-1))); do
      progress_log "INFO" "Waiting for worker $worker to complete..."
      while true; do
        if [ -f "$TEMP_DIR/node_${worker}_done" ]; then
          progress_log "INFO" "Worker $worker has completed"
          break
        fi
        sleep 2
      done
    done
    
    # Wait for cluster monitor to finish if it was started
    if [ "$ENABLE_CLUSTER_PROGRESS" = "true" ] && [ -n "$CLUSTER_MONITOR_PID" ]; then
      wait $CLUSTER_MONITOR_PID
    fi
    
    progress_log "INFO" "All workers have completed. Verifying object counts..."
    
    # Count objects in source and target buckets
    # List source bucket files
    rclone lsf $SOURCE_BUCKET --recursive --files-only > $TEMP_DIR/final_source_files.txt
    rclone lsf "$DEST_DIR" --recursive --files-only > "$TEMP_DIR/final_target_objects.txt"
    
    # Filter out directory entries and temp files
    TEMP_DIR_NAME=$(basename "$TEMP_DIR")
    grep -v "^${TEMP_DIR_NAME}/" "$TEMP_DIR/final_target_objects.txt" > "$TEMP_DIR/final_target_files.txt"
    
    # Extract just the object keys for comparison
    cat $TEMP_DIR/final_source_files.txt | awk '{print $NF}' | sort > $TEMP_DIR/source_keys.txt
    cat $TEMP_DIR/final_target_files.txt | awk '{print $NF}' | sort > $TEMP_DIR/target_keys.txt
    
    # Compare counts
    SOURCE_COUNT=$(wc -l < $TEMP_DIR/final_source_files.txt)
    TARGET_COUNT=$(wc -l < $TEMP_DIR/final_target_files.txt)
    
    # Calculate and print migration duration
    END_TIME=$(date +%s)
    DURATION=$((END_TIME - START_TIME))
    HOURS=$((DURATION / 3600))
    MINUTES=$(( (DURATION % 3600) / 60 ))
    SECONDS=$((DURATION % 60))
    
    echo "=================================================="
    echo "📊 Final Migration Statistics:"
    echo "Total migration time: ${HOURS}h ${MINUTES}m ${SECONDS}s"
    echo "Source bucket: $SOURCE_COUNT objects"
    echo "Target filesystem: $TARGET_COUNT objects"
    echo "=================================================="
    
    if [ $SOURCE_COUNT -eq $TARGET_COUNT ]; then
      progress_log "SUCCESS" "Migration completed successfully! Object counts match."
      
      # Even if counts match, check for differences in file lists
      if diff $TEMP_DIR/source_keys.txt $TEMP_DIR/target_keys.txt > $TEMP_DIR/diff_output.txt; then
        progress_log "SUCCESS" "All objects match between source and target."
      else
        progress_log "WARNING" "Although counts match, some objects differ between buckets."
        echo "Objects in source but not in target (first 10):"
        grep "^<" $TEMP_DIR/diff_output.txt | head -10
        echo "Objects in target but not in source (first 10):"
        grep "^>" $TEMP_DIR/diff_output.txt | head -10
      fi
    else
      progress_log "WARNING" "Migration completed with warnings. Object counts don't match."
      echo "Source: $SOURCE_COUNT, Target: $TARGET_COUNT"
      
      # Show detailed differences
      progress_log "INFO" "Analyzing differences between source and target buckets..."
      
      # Find files in source but not in target
      comm -23 $TEMP_DIR/source_keys.txt $TEMP_DIR/target_keys.txt > $TEMP_DIR/missing_in_target.txt
      MISSING_TARGET=$(wc -l < $TEMP_DIR/missing_in_target.txt)

      echo "$MISSING_TARGET files exist in source but not in target"
      
      if [ $MISSING_TARGET -gt 0 ]; then
        echo "Sample of missing files in target (first 10):"
        head -10 $TEMP_DIR/missing_in_target.txt
      fi
    fi
    
    # Clean up temporary dir
    #rm -rf $TEMP_DIR
  fi
  # end